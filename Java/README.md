# Machine-Learing

This is a collaborated work by Shaojie Wang and Qiuyuan Song.
Environment: Fedora(Linux version 4.12.13-300.fc26.x86_64); javac version 1.8.0_151.

## Guidance(steps)
- Open terminal under the extracted directory and `cd Machine-learning/src/`
- Under the `src/` directory, compile all the .java files with command `javac $(find . -name "*.java")`
- Still under the `src/`, run the program with the command lines attached at end of this README separately
- Expected output are in the writeup

## Notations
- Explanation of command line arguments:
    - For decision tree
        - On WillWaitProblem, only one argument: filename.
        - On IrisDataProblem, first argument is filename, second argument is fold number for cross validation.
    - For linear classifier
        - First argument is filename
        - Second argument is nsteps
        - Third argument is alpha (learning rate)
            - If this argument is above 0, then train the classifier with the exactly the given arguments.
            - Otherwise, we train the classifier with `nsteps = 100000`, and `alpha(t) = 1000 / (1000 + t)`.
    - For neural network
        - Suppose the length of arguments is n
        - Argument 1: filename
        - Argument 2: input layer dimension
        - Argument 3 to (n-5): hidden layers dimension
            - For example, if we capture only 1 argument in this range, like 7, then the hidden layer is a single layer with 7 units.
            - If we capture 2 arguments, like 7 5, then there are two hidden layers, first has 7 units and second has 5.
            - If we capture no arguments in this range, then there are no hidden layers at all. It is a linear classifier.
        - Argument (n-4): output layer dimension
        - Argument (n-3): epochs (how many times at most to execute the loop in training process)
        - Argument (n-2): alpha (learning rate)
        - Argument (n-1): stop threshold
            - Early stop threshold, which is a stop criteria in the training process.
            - Either the MSE reaches this given threshold, or the times of loop reach the max epochs, then the training process stops.
        - Argument n: the fold number for cross validation
            - Typically it is greater than 0.
            - If we set it 0, then the program will randomly devide the examples into two parts.
              One is training set, 70% of the dataset; the other is test set, the rest 30% of the dataset.
        
- Run the command lines under `src/`, because we specify the directory like `./dt/example/` to each our test examples.
- Results generated by Java on Windows platform may be different from those generated by Java on Linux system.
- Our test cases are different, so there are name notations for the following command lines sections.

## DEMO examples

- For decision tree:
```
java dt.example.WillWaitProblem ./dt/example/WillWait-data.txt
java dt.example.IrisDataProblem ./dt/example/iris.data.discrete.txt 10
```

- For linear classifier:
```
java lc.example.LogisticClassifierTest ./lc/example/earthquake-clean.data.txt 10000 0 10
java lc.example.LogisticClassifierTest ./lc/example/earthquake-noisy.data.txt 10000 0 10
java lc.example.LogisticClassifierTest ./lc/example/iris.data.txt 10000 0 10
java lc.example.PerceptronClassifierTest ./lc/example/earthquake-clean.data.txt 100 0 10
java lc.example.PerceptronClassifierTest ./lc/example/earthquake-noisy.data.txt 100 0 10
java lc.example.PerceptronClassifierTest ./lc/example/iris.data.txt 100 0 10
```

- For neural network:
```
java nn.core.MultiLayerBackPropagationNeuralNetwork ./nn/core/iris.data.txt 4 7 3 100 0.02 0.01 10
java nn.core.MultiLayerBackPropagationNeuralNetwork ./nn/core/iris.data.txt 4 7 5 3 1000 0.02 0.01 0
```